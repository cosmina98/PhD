{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZXwri3OZnkT5Cqy3x9W7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmina98/PhD/blob/main/Work_in_progress/MessPass_GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "u544FiWkIMCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgucepwTiKqg",
        "outputId": "1f3fe6b0-a616-46dd-cdb4-b30dfd255b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=07fe4fa2f2fca4a27dadb19172dacb299d09adb07533b6756e1455c4b086ff66\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n",
            "install: missing destination file operand after 'torch_geometric'\n",
            "Try 'install --help' for more information.\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.5 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install plotnine --quiet\n",
        "!pip install torch_geometric\n",
        "! install torch_geometric\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "metadata": {
        "id": "Lp5_AdSJi9X8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric \n",
        "from typing import Callable, List, Optional, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch import Tensor\n",
        "from torch.optim import Optimizer\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv,ChebConv,GATConv\n",
        "from torch_geometric.utils import softmax, add_remaining_self_loops\n",
        "#from torch_geometric.utils import accuracy\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from torch_geometric.utils import get_laplacian\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from plotnine import ggplot, geom_line, aes, xlab, theme, element_blank, ggtitle\n",
        "import scipy.sparse as sparse\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "R9T-RXjJVccy"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# libary imports \n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import operator\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "from torch.optim.adadelta import Adadelta\n",
        "from torch.optim.adagrad import Adagrad\n",
        "from torch.optim.adam import Adam\n",
        "from torch.optim.adamax import Adamax\n",
        "from torch.optim.adamw import AdamW\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.optim.sgd import SGD\n",
        "\n",
        "import torch_geometric \n",
        "from typing import Callable, List, Optional, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch import Tensor\n",
        "from torch.optim import Optimizer\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv,ChebConv\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from torch_geometric.utils import get_laplacian\n",
        "from torch_geometric.nn import MessagePassing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from plotnine import ggplot, geom_line, aes, xlab, theme, element_blank, ggtitle\n",
        "import scipy.sparse as sparse\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from dataclasses import dataclass\n",
        "import torch_geometric.utils\n",
        "#from torch_geometric.utils import accuracy\n"
      ],
      "metadata": {
        "id": "LjSZvaHkTw5k"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')\n"
      ],
      "metadata": {
        "id": "EDFDHjFSK64T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-r_NLLa8Lw7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset imports"
      ],
      "metadata": {
        "id": "DMM6naBmIQYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=list(range(3))\n",
        "i=0\n",
        "for dataset_name in ['Cora','CiteSeer','PubMed']:\n",
        "    dataset[i] = Planetoid('/tmp/dataset_name', name=dataset_name)\n",
        "    num_nodes = dataset[i].data.num_nodes\n",
        "    num_edges = dataset[i].data.num_edges // 2\n",
        "    train_len = dataset[i][0].train_mask.sum()\n",
        "    val_len = dataset[i][0].val_mask.sum()\n",
        "    test_len = dataset[i][0].test_mask.sum()\n",
        "    other_len = num_nodes - train_len - val_len - test_len\n",
        "    print(f\"Dataset: {dataset[i].name}\")\n",
        "    print(f\"Num. nodes: {num_nodes} (train={train_len}, val={val_len}, test={test_len}, other={other_len})\")\n",
        "    print(f\"Num. edges: {num_edges}\")\n",
        "    print(f\"Num. node features: {dataset[i].num_node_features}\")\n",
        "    print(f\"Num. classes: {dataset[i].num_classes}\")\n",
        "    print(f\"Dataset len.: {dataset[i].len()}\")\n",
        "    i=i+1\n",
        "    print(\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2iYQ5ggjCgm",
        "outputId": "ec1a574c-fe58-49af-9e8a-37168c427866"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Cora\n",
            "Num. nodes: 2708 (train=140, val=500, test=1000, other=1068)\n",
            "Num. edges: 5278\n",
            "Num. node features: 1433\n",
            "Num. classes: 7\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer\n",
            "Num. nodes: 3327 (train=120, val=500, test=1000, other=1707)\n",
            "Num. edges: 4552\n",
            "Num. node features: 3703\n",
            "Num. classes: 6\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: PubMed\n",
            "Num. nodes: 19717 (train=60, val=500, test=1000, other=18157)\n",
            "Num. edges: 44324\n",
            "Num. node features: 500\n",
            "Num. classes: 3\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing targets for each dataset"
      ],
      "metadata": {
        "id": "oMHbOMJ3XZwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d={0:{}, 1:{}, 2:{}}\n",
        "for i in range(3):\n",
        "    data=dataset[i]\n",
        "    X_train=data[0].x[data[0].train_mask]\n",
        "    d[i]['X_train']=X_train\n",
        "    y_train=data[0].y[data[0].train_mask]\n",
        "    d[i]['y_train']=y_train\n",
        "    X_test=data[0].x[data[0].test_mask]\n",
        "    d[i]['X_test']=X_test\n",
        "    y_test=data[0].y[data[0].test_mask]\n",
        "    d[i]['y_test']=y_test\n",
        "    X_val=data[0].x[data[0].val_mask]\n",
        "    d[i]['X_val']=X_val\n",
        "    y_val=data[0].y[data[0].val_mask]\n",
        "    d[i]['y_val']=X_val\n"
      ],
      "metadata": {
        "id": "9b51MCcaXZO7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Message Passing by inheriting MessagePassing class"
      ],
      "metadata": {
        "id": "wHYkJpEbqSOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_scatter import scatter_add\n",
        "\n",
        "dataset[0].data\n",
        "x=dataset[0].data.x\n",
        "edge_index=dataset[0].data.edge_index\n",
        "x_j = x[edge_index[0]]  # Source node features [num_edges, num_features]\n",
        "x_i = x[edge_index[1]]  # Target node features [num_edges, num_features]"
      ],
      "metadata": {
        "id": "sDfU-bp7wRba"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GATConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, alpha, drop_prob=0.0):\n",
        "        super().__init__(aggr=\"add\")\n",
        "        self.drop_prob = drop_prob\n",
        "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2*out_channels, 1)))\n",
        "        self.leakrelu = nn.LeakyReLU(alpha)\n",
        "        nn.init.xavier_uniform_(self.a)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = add_remaining_self_loops(edge_index)\n",
        "        #  Calculation  Wh\n",
        "        h = self.lin(x)\n",
        "        #  Start message propagation \n",
        "        h_prime = self.propagate(edge_index, x=h)\n",
        "        return h_prime\n",
        "\n",
        "    def message(self, x_i, x_j, edge_index_i):\n",
        "        #  Calculation a(Wh_i || wh_j)\n",
        "        e = torch.matmul((torch.cat([x_i, x_j], dim=-1)), self.a)\n",
        "        e = self.leakrelu(e)\n",
        "        alpha = softmax(e, edge_index_i)\n",
        "        alpha = F.dropout(alpha, self.drop_prob, self.training)\n",
        "        return x_j * alpha\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conv = GATConv(in_channels=3, out_channels=3, alpha=0.2)\n",
        "    x = torch.rand(4, 3)\n",
        "    edge_index = torch.tensor(\n",
        "        [[0, 1, 1, 2, 0, 2, 0, 3], [1, 0, 2, 1, 2, 0, 3, 0]], dtype=torch.long)\n",
        "    x = conv(x, edge_index)\n",
        "    print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_uZae2jqRve",
        "outputId": "faf7744f-a59f-4454-8776-c7e23f738908"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv = GATConv(x.shape[1], 256,alpha=0.2)\n",
        "m=conv(x, edge_index)\n",
        "m"
      ],
      "metadata": {
        "id": "rHaJN0H6qYNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a250154-4b22-4844-a8f8-b8cf8a2b7a2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0955, -0.0324,  0.1994,  ...,  0.1117,  0.0324,  0.0495],\n",
              "        [-0.1058, -0.0364,  0.2034,  ...,  0.1157,  0.0358,  0.0597],\n",
              "        [-0.1058, -0.0364,  0.2034,  ...,  0.1157,  0.0358,  0.0597],\n",
              "        [-0.0831, -0.0275,  0.1979,  ...,  0.1078,  0.0291,  0.0370]],\n",
              "       grad_fn=<ScatterAddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Message passing as torch.nn.moduke"
      ],
      "metadata": {
        "id": "7iXLAJW6wto8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "from torch_geometric.utils import softmax, add_remaining_self_loops\n",
        "\n",
        "class GATLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, alpha, dropout=0.0):\n",
        "        super().__init__()  \n",
        "        #initialisation\n",
        "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.flow = 'source_to_target'\n",
        "        self.out_channels=out_channels\n",
        "        self.drop_prob = dropout\n",
        "        self.leakrelu = nn.LeakyReLU(alpha)\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2*out_channels, 1)))\n",
        "        nn.init.xavier_uniform_(self.a)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def sum_aggregate(self,x,edge_index,num_nodes):\n",
        "        row,col=edge_index\n",
        "        tmp = torch.index_select(x, 0, row) # shape [num_edges, embed_size ]\n",
        "        index2 = col.expand(( self.out_channels, col.size(0))).T\n",
        "        # same result by using torch.scatter_add\n",
        "        aggr2 = torch.zeros(num_nodes, self.out_channels, dtype=tmp.dtype).scatter_add(0, index2, tmp)\n",
        "        return aggr2\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        num_nodes=len(x)\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = add_remaining_self_loops(edge_index)\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        z = self.lin(x)\n",
        "\n",
        "        # Step 4: Start propagating messages.\n",
        "        out=self.collect(z,edge_index)\n",
        "        x_j=out['x_j']\n",
        "        x_i= out['x_i']\n",
        "        edge_index_i= out['edge_index_i']\n",
        "        \n",
        "        #Step 5 Compute the attention score \n",
        "        e = self.leakrelu(torch.matmul((torch.cat([x_i, x_j], dim=-1)), self.a))\n",
        "        \n",
        "        #Step 6 Normalise the attention score\n",
        "        alpha = softmax(e, edge_index_i)\n",
        "        alpha = F.dropout(alpha, self.drop_prob, self.training)\n",
        "        \n",
        "        #Step 7 Compute the final message\n",
        "        out = self.message(x_j,alpha)\n",
        "\n",
        "        #Step 8 Aggregate messages \n",
        "        out= self.sum_aggregate(out,edge_index, num_nodes)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "    def collect(self ,x,edge_index):\n",
        "        i, j = (1, 0) if self.flow == 'source_to_target' else (0, 1)\n",
        "        out={}\n",
        "        # 2. construct message x_j, x_i. Both with shape [num_edge, embed_size]\n",
        "        out['x_j'] = x.index_select(0, edge_index[i]) \n",
        "        out['x_i'] = x.index_select(0, edge_index[j])\n",
        "        out['edge_index_i'] = edge_index[i] # Source node edges \n",
        "        out['edge_index_j'] = edge_index[j]   # Target node edges \n",
        "        return out  \n",
        "\n",
        "   \n",
        "    def message(self, x_j,alpha):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        return x_j * alpha\n",
        "\n",
        "    #'not needed'\n",
        "    def update(self, aggr_out):\n",
        "    # aggr_out has shape [num_nodes, out_channels]\n",
        "\n",
        "    # Step 5: Return new node embeddings.\n",
        "        return aggr_out"
      ],
      "metadata": {
        "id": "b7U-mb1VqYP-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = GATLayer(x.shape[1], 256,alpha=0.2)\n",
        "m=conv(x, edge_index)\n",
        "m"
      ],
      "metadata": {
        "id": "MezJYbpxqYSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabff96c-25e4-44d6-8c85-6e020b53647e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0545, -0.1748, -0.2349,  ...,  0.0624, -0.2049, -0.2106],\n",
              "        [ 0.0403, -0.1284, -0.1723,  ...,  0.0458, -0.1508, -0.1547],\n",
              "        [ 0.0403, -0.1284, -0.1723,  ...,  0.0458, -0.1508, -0.1547],\n",
              "        [ 0.0284, -0.0927, -0.1250,  ...,  0.0330, -0.1081, -0.1118]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self,num_features,num_classes):\n",
        "        super(GAT, self).__init__()\n",
        "        self.hid = 8\n",
        "        self.in_head = 8\n",
        "        self.out_head = 1\n",
        "\n",
        "        self.conv1 = GATLayer(num_features, self.hid, dropout=0.6,alpha=0.2)\n",
        "        self.conv2 = GATLayer(self.hid*self.in_head, num_classes,\n",
        "                             dropout=0.6,alpha=0.2)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "                \n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "5fECBRtWqYUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(GAT(dataset[0].num_node_features, dataset[0].num_classes))\n",
        "print(GAT(dataset[1].num_node_features, dataset[1].num_classes))\n",
        "print(GAT(dataset[2].num_node_features, dataset[2].num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESZBnPNxCwTG",
        "outputId": "fe1a01db-ec74-41ec-90f4-c3d378990135"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (conv1): GATLayer(\n",
            "    (lin): Linear(in_features=1433, out_features=8, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv2): GATLayer(\n",
            "    (lin): Linear(in_features=64, out_features=7, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "GAT(\n",
            "  (conv1): GATLayer(\n",
            "    (lin): Linear(in_features=3703, out_features=8, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv2): GATLayer(\n",
            "    (lin): Linear(in_features=64, out_features=6, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "GAT(\n",
            "  (conv1): GATLayer(\n",
            "    (lin): Linear(in_features=500, out_features=8, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv2): GATLayer(\n",
            "    (lin): Linear(in_features=64, out_features=3, bias=False)\n",
            "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}