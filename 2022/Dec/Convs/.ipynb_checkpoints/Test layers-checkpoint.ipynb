{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c048e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter, Module\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch.optim import Optimizer\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.optim.sgd import SGD\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv,ChebConv,GATConv\n",
    "from torch_geometric.utils import get_laplacian\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix,degree,add_self_loops\n",
    "from torch_geometric.nn import GatedGraphConv\n",
    "from torch_geometric.nn import MessagePassing, SAGEConv, GINConv, global_add_pool\n",
    "from torch.optim.adam import Adam\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import os.path as osp\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "from typing_extensions import Literal, TypedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import  math\n",
    "import itertools\n",
    "from functools import reduce\n",
    "import operator\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from torch.utils.data import Subset\n",
    "from plotnine import ggplot, geom_line, aes, xlab, theme, element_blank, ggtitle\n",
    "from collections import OrderedDict\n",
    "from typing_extensions import Literal, TypedDict\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_scatter import gather_csr, scatter, segment_csr\n",
    "import inspect\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn.inits import uniform\n",
    "device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b9d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora\n",
      "Num. nodes: 2708 (train=140, val=500, test=1000, other=1068)\n",
      "Num. edges: 5278\n",
      "Num. node features: 1433\n",
      "Num. classes: 7\n",
      "Dataset len.: 1\n",
      " \n",
      "Dataset: CiteSeer\n",
      "Num. nodes: 3327 (train=120, val=500, test=1000, other=1707)\n",
      "Num. edges: 4552\n",
      "Num. node features: 3703\n",
      "Num. classes: 6\n",
      "Dataset len.: 1\n",
      " \n",
      "Dataset: PubMed\n",
      "Num. nodes: 19717 (train=60, val=500, test=1000, other=18157)\n",
      "Num. edges: 44324\n",
      "Num. node features: 500\n",
      "Num. classes: 3\n",
      "Dataset len.: 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "dataset=list(range(3))\n",
    "i=0\n",
    "for dataset_name in ['Cora','CiteSeer','PubMed']:\n",
    "    dataset[i] = Planetoid('/tmp/dataset_name', name=dataset_name)\n",
    "    num_nodes = dataset[i].data.num_nodes\n",
    "    num_edges = dataset[i].data.num_edges // 2\n",
    "    train_len = dataset[i][0].train_mask.sum()\n",
    "    val_len = dataset[i][0].val_mask.sum()\n",
    "    test_len = dataset[i][0].test_mask.sum()\n",
    "    other_len = num_nodes - train_len - val_len - test_len\n",
    "    print(f\"Dataset: {dataset[i].name}\")\n",
    "    print(f\"Num. nodes: {num_nodes} (train={train_len}, val={val_len}, test={test_len}, other={other_len})\")\n",
    "    print(f\"Num. edges: {num_edges}\")\n",
    "    print(f\"Num. node features: {dataset[i].num_node_features}\")\n",
    "    print(f\"Num. classes: {dataset[i].num_classes}\")\n",
    "    print(f\"Dataset len.: {dataset[i].len()}\")\n",
    "    i=i+1\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa11b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCN import GCNConv1\n",
    "from GraphSage import GraphSage1\n",
    "from GAT import GATLayer,GAT1\n",
    "from GIN import GIN1\n",
    "from Gated_Graph import GatedGraphConv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970e582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of row values without normalization: tensor([ 9., 23., 19.,  ..., 18., 14., 13.])\n",
      "Sum of row values with normalization: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n",
      " \n",
      "Sum of row values without normalization: tensor([31., 33., 25.,  ..., 40., 36., 26.])\n",
      "Sum of row values with normalization: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n",
      " \n",
      "Sum of row values without normalization: tensor([1.5913, 1.6492, 1.8888,  ..., 1.7013, 2.0314, 1.8369])\n",
      "Sum of row values with normalization: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "dataset[0] = Planetoid(\"/tmp/Cora\", name=\"Cora\")\n",
    "print(f\"Sum of row values without normalization: {dataset[0][0].x.sum(dim=-1)}\")\n",
    "\n",
    "dataset[0] = Planetoid(\"/tmp/Cora\", name=\"Cora\", transform=T.NormalizeFeatures())\n",
    "print(f\"Sum of row values with normalization: {dataset[0][0].x.sum(dim=-1)}\")\n",
    "print(\" \")\n",
    "\n",
    "dataset[1] = Planetoid(\"/tmp/CiteSeer\", name=\"CiteSeer\")\n",
    "print(f\"Sum of row values without normalization: {dataset[1][0].x.sum(dim=-1)}\")\n",
    "\n",
    "dataset[1] = Planetoid(\"/tmp/CiteSeer\", name=\"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "print(f\"Sum of row values with normalization: {dataset[1][0].x.sum(dim=-1)}\")\n",
    "print(\" \")\n",
    "\n",
    "dataset[2] = Planetoid(\"/tmp/PubMed\", name=\"PubMed\")\n",
    "print(f\"Sum of row values without normalization: {dataset[2][0].x.sum(dim=-1)}\")\n",
    "\n",
    "dataset[2] = Planetoid(\"/tmp/PubMed\", name=\"PubMed\", transform=T.NormalizeFeatures())\n",
    "print(f\"Sum of row values with normalization: {dataset[2][0].x.sum(dim=-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].data\n",
    "x=dataset[0].data.x\n",
    "edge_index=dataset[0].data.edge_index\n",
    "x_j = x[edge_index[0]]  # Source node features [num_edges, num_features]\n",
    "x_i = x[edge_index[1]]  # Target node features [num_edges, num_features]\n",
    "edge_weight = dataset[0][0].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d569f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0350,  0.0365,  0.0213,  ...,  0.0004, -0.0177,  0.0379],\n",
       "        [ 0.0251,  0.0089, -0.0019,  ..., -0.0151,  0.0075, -0.0395],\n",
       "        [ 0.0394, -0.0467,  0.0288,  ..., -0.0768,  0.0271, -0.0199],\n",
       "        ...,\n",
       "        [ 0.0062,  0.0267, -0.0409,  ..., -0.0609,  0.0048,  0.0132],\n",
       "        [ 0.0092, -0.0134,  0.0299,  ...,  0.0325, -0.0216,  0.0248],\n",
       "        [-0.0303, -0.0098,  0.0325,  ...,  0.0260,  0.0036,  0.0358]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = GCNConv1(x.shape[1], 256)\n",
    "m=conv(x, edge_index)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca83198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_scatter import scatter\n",
    "\n",
    "row,col=edge_index\n",
    "tmp = torch.index_select(x, 0, row) # shape [num_edges, embed_size)\n",
    "print(x)\n",
    "\n",
    "scatter(tmp,col,0,reduce='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d061808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0099, -0.0428,  0.0521,  ..., -0.0081,  0.0128,  0.0340],\n",
       "        [-0.0379, -0.0319,  0.0353,  ...,  0.0403, -0.0064,  0.0402],\n",
       "        [ 0.0089, -0.0235,  0.0215,  ...,  0.0124, -0.0331,  0.0609],\n",
       "        ...,\n",
       "        [ 0.0148,  0.0193,  0.0295,  ..., -0.0048, -0.0463,  0.0086],\n",
       "        [-0.0083,  0.0003,  0.0549,  ..., -0.0021, -0.0542,  0.0373],\n",
       "        [ 0.0167, -0.0151,  0.0514,  ...,  0.0109, -0.0298,  0.0511]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = GCNConv1(x.shape[1], 256)\n",
    "m=conv(x, edge_index)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed06a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0630,  0.1184,  0.0699,  ...,  0.0465,  0.0201, -0.0515],\n",
       "        [-0.0682, -0.1258,  0.0597,  ..., -0.0602,  0.1336, -0.0439],\n",
       "        [-0.0617,  0.0100,  0.0887,  ...,  0.0439, -0.0041, -0.0044],\n",
       "        ...,\n",
       "        [-0.0070, -0.1240, -0.1032,  ..., -0.0888,  0.0608,  0.1321],\n",
       "        [-0.0013, -0.0262,  0.0864,  ..., -0.0203, -0.0224,  0.1229],\n",
       "        [-0.0494, -0.0029,  0.0439,  ..., -0.0099, -0.0562, -0.0434]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = GraphSage1(x.shape[1], 256)\n",
    "m=conv(x, edge_index)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa7363c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0041, -0.0238, -0.0438,  ...,  0.0266,  0.0658, -0.0354],\n",
       "        [ 0.0282,  0.0568, -0.0563,  ...,  0.0021, -0.0088, -0.0283],\n",
       "        [ 0.0399,  0.0146, -0.0619,  ...,  0.0085,  0.0057, -0.0197],\n",
       "        ...,\n",
       "        [-0.0060, -0.0782, -0.0413,  ..., -0.0004, -0.0373, -0.0750],\n",
       "        [ 0.0807, -0.0185,  0.0122,  ..., -0.0332, -0.0137, -0.0223],\n",
       "        [ 0.0762, -0.0301,  0.0151,  ..., -0.0125,  0.0137, -0.0092]],\n",
       "       grad_fn=<ScatterAddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "conv = GATLayer(dataset[0].num_node_features, dataset[0].num_classes, dropout=0.0,alpha=0.0)\n",
    "m=conv(x, edge_index)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14843fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT1(\n",
      "  (conv1): GATLayer(\n",
      "    (lin): Linear(in_features=1433, out_features=8, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv2): GATLayer(\n",
      "    (lin): Linear(in_features=64, out_features=7, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n",
      "GAT1(\n",
      "  (conv1): GATLayer(\n",
      "    (lin): Linear(in_features=3703, out_features=8, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv2): GATLayer(\n",
      "    (lin): Linear(in_features=64, out_features=6, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n",
      "GAT1(\n",
      "  (conv1): GATLayer(\n",
      "    (lin): Linear(in_features=500, out_features=8, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv2): GATLayer(\n",
      "    (lin): Linear(in_features=64, out_features=3, bias=False)\n",
      "    (leakrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(GAT1(dataset[0].num_node_features, dataset[0].num_classes))\n",
    "print(GAT1(dataset[1].num_node_features, dataset[1].num_classes))\n",
    "print(GAT1(dataset[2].num_node_features, dataset[2].num_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfa930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNConv(1433, 7)\n"
     ]
    }
   ],
   "source": [
    "print(GCNConv(dataset[0].num_node_features, dataset[0].num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359b795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5626, 0.4471, 0.4731,  ..., 0.5281, 0.5183, 0.4994],\n",
       "        [0.5561, 0.5008, 0.5252,  ..., 0.5248, 0.5046, 0.5057],\n",
       "        [0.7020, 0.5398, 0.4814,  ..., 0.5258, 0.4502, 0.6831],\n",
       "        ...,\n",
       "        [0.5236, 0.4597, 0.5327,  ..., 0.4877, 0.5030, 0.5135],\n",
       "        [0.5704, 0.4814, 0.4808,  ..., 0.5040, 0.5133, 0.5513],\n",
       "        [0.6135, 0.5591, 0.4562,  ..., 0.5210, 0.5264, 0.6143]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = GIN1(x.shape[1], 256)\n",
    "m=conv(x, edge_index)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e9d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0068, -0.0038,  0.0027,  ...,  0.0010, -0.0058, -0.0039],\n",
       "        [-0.0087, -0.0011,  0.0027,  ..., -0.0004, -0.0057, -0.0043],\n",
       "        [-0.0747, -0.0372,  0.0308,  ...,  0.0582, -0.0250,  0.0218],\n",
       "        ...,\n",
       "        [-0.0131, -0.0027,  0.0006,  ..., -0.0045, -0.0028, -0.0047],\n",
       "        [-0.0125,  0.0067,  0.0025,  ...,  0.0138, -0.0139, -0.0045],\n",
       "        [-0.0019, -0.0041,  0.0056,  ...,  0.0047,  0.0030,  0.0022]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping out records as it is too slow \n",
    "mask = F.dropout(torch.ones(edge_index.shape[1]), 0.5) > 0\n",
    "edge_index_to_use = edge_index[:, mask]\n",
    "edge_attr_to_use = edge_weight[mask] if edge_weight is not None else None\n",
    "(edge_index_to_use.shape)\n",
    "conv = GatedGraphConv1(x.shape[1], 6000)\n",
    "m=conv(x, edge_index_to_use,edge_attr_to_use)\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ea58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd85754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ebf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f7f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
