{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wrapped up MLP.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnz5H3QjAMTjmPEFEwL3XL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10e64bf020754833be8b3b72f585a19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c60c8d210a224bed8674ca3ad1df2e3d",
              "IPY_MODEL_a7c54e08ad744e549b88b911a3c54b3e",
              "IPY_MODEL_2815303ac1914166b165e1e063619136"
            ],
            "layout": "IPY_MODEL_d90af53dd4014cb09d18da20339ab083"
          }
        },
        "c60c8d210a224bed8674ca3ad1df2e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90a753f17a846cb8e35aff4fc59d170",
            "placeholder": "​",
            "style": "IPY_MODEL_98a98d128f6a4bb09497353a17522f63",
            "value": "100%"
          }
        },
        "a7c54e08ad744e549b88b911a3c54b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911b6c522c824dbcaad2c640858db80c",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8022958b19b648149572fcba91eb88df",
            "value": 170498071
          }
        },
        "2815303ac1914166b165e1e063619136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316106912a2f45eb9945dd7a8eed21b4",
            "placeholder": "​",
            "style": "IPY_MODEL_83bb7f16ddee466e9cdd5bcc58c37eda",
            "value": " 170498071/170498071 [00:03&lt;00:00, 56290404.79it/s]"
          }
        },
        "d90af53dd4014cb09d18da20339ab083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90a753f17a846cb8e35aff4fc59d170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a98d128f6a4bb09497353a17522f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911b6c522c824dbcaad2c640858db80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8022958b19b648149572fcba91eb88df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "316106912a2f45eb9945dd7a8eed21b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83bb7f16ddee466e9cdd5bcc58c37eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmina98/PhD/blob/main/MLP_on_graph_classification_using_PyTorch/Wrapped_up_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw Pytorch"
      ],
      "metadata": {
        "id": "8N4y-K7EMeQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning --quiet\n"
      ],
      "metadata": {
        "id": "aFdqy2COLpqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda45222-58b7-4ff6-ab63-8fb25a41805c"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 585 kB 15.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "pEgfjtTkLt88"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# libary imports \n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import time\n"
      ],
      "metadata": {
        "id": "8aGeFmP-LjRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "UIHZj09aLam0"
      },
      "outputs": [],
      "source": [
        "#definining the MLP class\n",
        "class MLP(nn.Module):\n",
        "  '''\n",
        "    Multilayer Perceptron.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(32 * 32 * 3, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 10)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Forward pass'''\n",
        "    return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download and normalise data\n",
        "torch.manual_seed(42)\n",
        "ROOT = '.data'\n",
        "\n",
        "\n",
        "# Prepare CIFAR-10 dataset\n",
        "trainset = CIFAR10(os.getcwd(), download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = CIFAR10(os.getcwd(), download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-vsKdphL-l0",
        "outputId": "1f6d73ca-33f1-474c-a1d8-a868d4e3e659"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the MLP\n",
        "mlp = MLP()\n",
        "  \n",
        "# Define the loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-3,momentum=0.9 , nesterov=True, weight_decay=0)\n",
        "optimizer_2 = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "7_vhNk36MBUe"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(optimizer):\n",
        "    for epoch in range(2):  # loop over the dataset 2 times\n",
        "\n",
        "       running_loss = 0.0\n",
        "       for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + compute loss+ backward + optimize\n",
        "        outputs = mlp(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test(model):\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "              'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            estimation, predictions = torch.max(outputs, 1)\n",
        "            print(np.log(estimation))\n",
        "            # collect the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "jdYbLjLLMOXw"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(optimizer)\n",
        "test(mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pmL7CYwMT0H",
        "outputId": "517e7d63-cf4b-4118-8883-7250b09ee72f"
      },
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.459\n",
            "[1,  4000] loss: 1.413\n",
            "[1,  6000] loss: 1.427\n",
            "[2,  2000] loss: 1.391\n",
            "[2,  4000] loss: 1.352\n",
            "[2,  6000] loss: 1.373\n",
            "Finished Training\n",
            "Accuracy for class: plane is 50.5 %\n",
            "Accuracy for class: car   is 66.5 %\n",
            "Accuracy for class: bird  is 32.4 %\n",
            "Accuracy for class: cat   is 49.2 %\n",
            "Accuracy for class: deer  is 44.1 %\n",
            "Accuracy for class: dog   is 30.5 %\n",
            "Accuracy for class: frog  is 61.7 %\n",
            "Accuracy for class: horse is 71.3 %\n",
            "Accuracy for class: ship  is 71.2 %\n",
            "Accuracy for class: truck is 60.3 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tDVKqVeYMdvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrapped up Pytorch"
      ],
      "metadata": {
        "id": "0TQiS-VaMemq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CIFAR-10 dataset\n",
        "trainset = CIFAR10(os.getcwd(), download=True, transform=transforms.Compose(\n",
        "      [transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = CIFAR10(os.getcwd(), download=True, transform=transforms.Compose(\n",
        "      [transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "10e64bf020754833be8b3b72f585a19f",
            "c60c8d210a224bed8674ca3ad1df2e3d",
            "a7c54e08ad744e549b88b911a3c54b3e",
            "2815303ac1914166b165e1e063619136",
            "d90af53dd4014cb09d18da20339ab083",
            "c90a753f17a846cb8e35aff4fc59d170",
            "98a98d128f6a4bb09497353a17522f63",
            "911b6c522c824dbcaad2c640858db80c",
            "8022958b19b648149572fcba91eb88df",
            "316106912a2f45eb9945dd7a8eed21b4",
            "83bb7f16ddee466e9cdd5bcc58c37eda"
          ]
        },
        "id": "4KCxWWGde6bl",
        "outputId": "c377599c-e9ca-46d1-99ef-46d235f959f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10e64bf020754833be8b3b72f585a19f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/cifar-10-python.tar.gz to /content\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__ (self):\n",
        "       \n",
        "      self.batch_size=2000\n",
        "      self.epochs=2\n",
        "      #used for label count \n",
        "      self.num_classes=0\n",
        "      self.verbose=True\n",
        "        \n",
        "      self.loss_function = nn.CrossEntropyLoss()\n",
        "       \n",
        "      #common  to most optimsers\n",
        "      self.learning_rate=1e-3\n",
        "      self.weight_decay=0\n",
        "      self.running_loss = 0.0\n",
        "    \n",
        "      #for sgd  type of optimisers\n",
        "     \n",
        "      #error when trying to set the momentum using self.momentum\n",
        "      self.nesterov= True,\n",
        "      self.dampening=0\n",
        "     \n",
        "      #for adam optimiser\n",
        "      self.betas=(0.9,0.99)\n",
        "      self.eps=1e-8\n",
        "      self.amsgrad=False\n",
        "\n",
        "      self.mlp=self.MLP()\n",
        "      self.optimiser=None\n",
        "\n",
        "    class MLP(nn.Module):\n",
        "      '''\n",
        "        Multilayer Perceptron.\n",
        "      '''\n",
        "      def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(32 * 32 * 3, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 32),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(32, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        '''Forward pass'''\n",
        "        return self.layers(x)\n",
        "\n",
        "    def print_self(self):\n",
        "        print(mlp)\n",
        "          \n",
        "    def set_optimiser(self,optimiser_choice):\n",
        "        #playing around with adam and sgd only at the moment\n",
        "        #there is only two of them \n",
        "        \n",
        "        if optimiser_choice.lower().strip()=='adam':\n",
        "          self.optimiser=torch.optim.Adam(self.mlp.parameters(),lr=self.learning_rate, betas=self.betas, eps=self.eps, weight_decay=self.weight_decay, amsgrad=self.amsgrad)\n",
        "        elif optimiser_choice.lower().strip()=='sgd':\n",
        "          self.optimiser=torch.optim.SGD(self.mlp.parameters(),lr=self.learning_rate, weight_decay=self.weight_decay, momentum=0.9,nesterov=self.nesterov , dampening=self.dampening)\n",
        "          return self.optimiser\n",
        "\n",
        "\n",
        "\n",
        "    def get_params(self): #get parameters\n",
        "       if (self.optimiser != None) :\n",
        "         return  (self.props(),self.optimiser.state_dict(), self.mlp.state_dict)\n",
        "       else: return self.mlp.state_dict() \n",
        "  \n",
        "    def fit(self,trainloader):\n",
        "        for epoch in range(self.epochs):  # loop over the dataset 2 times\n",
        "\n",
        "          running_loss =self.running_loss\n",
        "          for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "             \n",
        "            # zero the parameter gradients\n",
        "            self.optimiser.zero_grad()\n",
        "\n",
        "            # forward + compute loss+ backward + optimize\n",
        "            outputs = self.mlp(inputs)\n",
        "            loss = self.loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimiser.step()\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % self.batch_size == 1999:    # print every 2000 mini-batches\n",
        "                if self.verbose==True:\n",
        "                  print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / self.batch_size:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "\n",
        "    def predict(self,testloader): #Predict using the multi-layer perceptron classifier.\n",
        "      prediction_list=[]\n",
        "      # again no gradients needed\n",
        "      with torch.no_grad():\n",
        "          for data in testloader:\n",
        "              images, labels = data\n",
        "              outputs = self.mlp(images)\n",
        "              estimation, predictions = torch.max(outputs, 1)\n",
        "              prediction_list.append(predictions)\n",
        "      return prediction_list #torch.stack(prediction_list)\n",
        "\n",
        "\n",
        "    def predict_log_proba(self,loader):  #\tReturn the log of probability estimates.\n",
        "        y_prob=self.predict_proba(loader)\n",
        "        log_proba=np.log(y_prob)\n",
        "        return log_proba\n",
        " \n",
        "\n",
        "    def predict_proba(self,loader):\t#Probability estimates.\n",
        "      probabilities_list=[]\n",
        "      # again no gradients needed\n",
        "      with torch.no_grad():\n",
        "          for data in loader:\n",
        "              images, labels = data\n",
        "              outputs = self.mlp(images)\n",
        "              estimation, predictions = torch.max(outputs, 1)\n",
        "              probabilities_list.append(estimation)\n",
        "      return probabilities_list\n",
        "      \n",
        "\n",
        "    def score(self,loader): #Return the mean accuracy on the given test data and labels.\n",
        "        prediction_list=[]\n",
        "        if self.num_classes==0:\n",
        "            classes = ('plane', 'car', 'bird', 'cat',\n",
        "                    'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "            # prepare to count predictions for each class\n",
        "            correct_pred = {classname: 0 for classname in classes}\n",
        "            total_pred = {classname: 0 for classname in classes}\n",
        "        #use the class number as key\n",
        "        else: \n",
        "            classes=tuple(np.arange(self.num_classes))  \n",
        "            correct_pred = {classname: 0 for classname in np.arange(num_classes)}\n",
        "            total_pred= {classname: 0 for classname in np.arange(num_classes)}\n",
        "\n",
        "        # again no gradients needed\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                images, labels = data\n",
        "                outputs = self.mlp(images)\n",
        "                estimation, predictions = torch.max(outputs, 1)\n",
        "                prediction_list.append(predictions)\n",
        "                # collect the correct predictions for each class\n",
        "                for label, prediction in zip(labels, predictions):\n",
        "                    if label == prediction:\n",
        "                        correct_pred[classes[label]] += 1\n",
        "                    total_pred[classes[label]] += 1\n",
        "        accuracies={}\n",
        "        # print accuracy for each class\n",
        "        for classname, correct_count in correct_pred.items():\n",
        "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "            accuracies[classname]=accuracy\n",
        "            if self.verbose:\n",
        "              print(f'Accuracy for class: {classname} is {accuracy:.1f} %')\n",
        "        \n",
        "\n",
        "    def set_params(self, attr, value): #sets parameters\n",
        "        setattr(self, attr, value)\n",
        "        \n",
        "    def props(cls):   \n",
        "        return [i for i in cls.__dict__.items() if i[:1] != '_']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JK6isQN_OIq0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Trainer()\n",
        "model.set_optimiser('adam')\n",
        "model.set_params('verbose', False)\n",
        "model.get_params()\n",
        "model.fit(trainloader)\n",
        "model.predict(testloader)\n",
        "model.score(testloader)\n",
        "model.predict_log_proba(testloader)\n",
        "model.predict_log_proba(testloader)"
      ],
      "metadata": {
        "id": "govYeZQ7urGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l2-v4_zat9Le"
      },
      "execution_count": 383,
      "outputs": []
    }
  ]
}