{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYX0xTOrXL9q7Vnf7+LL2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmina98/PhD/blob/main/2023/Feb/GRAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cosmina98/GRAN\n",
        "!cd GRAN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugrDaEc1gNHz",
        "outputId": "6aa73a87-5311-4af0-eff2-9822b5e4eb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GRAN'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 144 (delta 4), reused 0 (delta 0), pack-reused 132\u001b[K\n",
            "Receiving objects: 100% (144/144), 7.83 MiB | 12.74 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "pNlD0loIMxKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH-xc_oajqGa",
        "outputId": "9f2a1c49-b9c9-489a-be05-86cb726ac6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mGRAN\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r GRAN/requirements.txt\n"
      ],
      "metadata": {
        "id": "NfVVl418fVeB",
        "outputId": "04bd41c1-98b8-4d4f-ca9d-f48a94304b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting networkx==2.3\n",
            "  Downloading networkx-2.3.zip (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 3)) (4.64.1)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 5)) (1.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 6)) (6.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 7)) (1.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r GRAN/requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from networkx==2.3->-r GRAN/requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pyemd->-r GRAN/requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->-r GRAN/requirements.txt (line 4)) (3.19.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r GRAN/requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r GRAN/requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r GRAN/requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r GRAN/requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->-r GRAN/requirements.txt (line 8)) (1.15.0)\n",
            "Building wheels for collected packages: networkx\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556009 sha256=cd7a8e65cd516105dcd54a01a5f17c3a54d7a7a499287c8e3a62595702050c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/62/9e/0ed2d25fd4f5761e2d19568cda0c32716556dfa682e65ecf64\n",
            "Successfully built networkx\n",
            "Installing collected packages: tensorboardX, networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "Successfully installed networkx-2.3 tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN4L7fPD1Qsp",
        "outputId": "21371b23-6d81-492d-87c7-8a28d59d8e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mGRAN\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd GRAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LILXgmUi2Qmj",
        "outputId": "e3c386b6-0b0f-4cb1-eaaa-dfdd5699801d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'GRAN'\n",
            "/content/GRAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_exp.py -c config/gran_lobster.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shojTHdCjebC",
        "outputId": "5e49b72c-005c-40a3-ede3-f6585a1eb417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO  | 2023-02-10 19:48:46,958 | run_exp.py                | line 26   : Writing log file to exp/GRAN/GRANMixtureBernoulli_lobster_2023-Feb-10-19-48-46_365/log_exp_365.txt\n",
            "INFO  | 2023-02-10 19:48:46,958 | run_exp.py                | line 27   : Exp instance id = 365\n",
            "INFO  | 2023-02-10 19:48:46,958 | run_exp.py                | line 28   : Exp comment = None\n",
            "INFO  | 2023-02-10 19:48:46,958 | run_exp.py                | line 29   : Config =\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "{'dataset': {'data_path': 'data/',\n",
            "             'dev_ratio': 0.2,\n",
            "             'has_node_feat': False,\n",
            "             'is_overwrite_precompute': False,\n",
            "             'is_sample_subgraph': False,\n",
            "             'is_save_split': False,\n",
            "             'loader_name': 'GRANData',\n",
            "             'name': 'lobster',\n",
            "             'node_order': 'DFS',\n",
            "             'num_fwd_pass': 1,\n",
            "             'num_subgraph_batch': 25,\n",
            "             'train_ratio': 0.8},\n",
            " 'device': 'cuda:0',\n",
            " 'exp_dir': 'exp/GRAN',\n",
            " 'exp_name': 'GRANMixtureBernoulli_lobster_2023-Feb-10-19-48-46_365',\n",
            " 'gpus': [0],\n",
            " 'model': {'block_size': 1,\n",
            "           'dimension_reduce': True,\n",
            "           'edge_weight': 1.0,\n",
            "           'embedding_dim': 128,\n",
            "           'has_attention': True,\n",
            "           'hidden_dim': 128,\n",
            "           'is_sym': True,\n",
            "           'max_num_nodes': 100,\n",
            "           'name': 'GRANMixtureBernoulli',\n",
            "           'num_GNN_layers': 7,\n",
            "           'num_GNN_prop': 1,\n",
            "           'num_canonical_order': 1,\n",
            "           'num_mix_component': 20,\n",
            "           'sample_stride': 1},\n",
            " 'run_id': '365',\n",
            " 'runner': 'GranRunner',\n",
            " 'save_dir': 'exp/GRAN/GRANMixtureBernoulli_lobster_2023-Feb-10-19-48-46_365',\n",
            " 'seed': 1234,\n",
            " 'test': {'batch_size': 20,\n",
            "          'better_vis': False,\n",
            "          'is_single_plot': False,\n",
            "          'is_test_ER': False,\n",
            "          'is_vis': True,\n",
            "          'num_test_gen': 100,\n",
            "          'num_vis': 9,\n",
            "          'num_workers': 0,\n",
            "          'test_model_dir': 'snapshot_model',\n",
            "          'test_model_name': 'gran_lobster.pth',\n",
            "          'vis_num_row': 3},\n",
            " 'train': {'batch_size': 20,\n",
            "           'display_iter': 10,\n",
            "           'is_resume': False,\n",
            "           'lr': 0.0001,\n",
            "           'lr_decay': 0.3,\n",
            "           'lr_decay_epoch': [100000000],\n",
            "           'max_epoch': 100000,\n",
            "           'momentum': 0.9,\n",
            "           'num_workers': 8,\n",
            "           'optimizer': 'Adam',\n",
            "           'resume_dir': None,\n",
            "           'resume_epoch': 5000,\n",
            "           'resume_model': 'model_snapshot_0005000.pth',\n",
            "           'shuffle': True,\n",
            "           'snapshot_epoch': 1000,\n",
            "           'valid_epoch': 50,\n",
            "           'wd': 0.0},\n",
            " 'use_gpu': True,\n",
            " 'use_horovod': False}\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "max # nodes = 100 || mean # nodes = 50.22\n",
            "max # edges = 99 || mean # edges = 49.22\n",
            "INFO  | 2023-02-10 19:48:47,094 | gran_runner.py            | line 123  : Train/val/test = 80/20/20\n",
            "INFO  | 2023-02-10 19:48:47,095 | gran_runner.py            | line 136  : No Edges vs. Edges in training set = 61.07329707329707\n",
            "\r  0% 0/80 [00:00<?, ?it/s]\r 72% 58/80 [00:00<00:00, 578.67it/s]\r100% 80/80 [00:00<00:00, 578.87it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "INFO  | 2023-02-10 19:48:54,835 | gran_runner.py            | line 266  : NLL Loss @ epoch 0001 iteration 00000001 = 0.6922523379325867\n",
            "INFO  | 2023-02-10 19:49:01,659 | gran_runner.py            | line 266  : NLL Loss @ epoch 0003 iteration 00000010 = 0.6499835252761841\n",
            "INFO  | 2023-02-10 19:49:07,946 | gran_runner.py            | line 266  : NLL Loss @ epoch 0005 iteration 00000020 = 0.5785976648330688\n",
            "INFO  | 2023-02-10 19:49:16,726 | gran_runner.py            | line 266  : NLL Loss @ epoch 0008 iteration 00000030 = 0.504304826259613\n",
            "INFO  | 2023-02-10 19:49:22,757 | gran_runner.py            | line 266  : NLL Loss @ epoch 0010 iteration 00000040 = 0.4555639922618866\n",
            "INFO  | 2023-02-10 19:49:31,584 | gran_runner.py            | line 266  : NLL Loss @ epoch 0013 iteration 00000050 = 0.3358132839202881\n",
            "INFO  | 2023-02-10 19:49:38,249 | gran_runner.py            | line 266  : NLL Loss @ epoch 0015 iteration 00000060 = 0.26484617590904236\n",
            "INFO  | 2023-02-10 19:49:46,845 | gran_runner.py            | line 266  : NLL Loss @ epoch 0018 iteration 00000070 = 0.2609400749206543\n",
            "INFO  | 2023-02-10 19:49:54,048 | gran_runner.py            | line 266  : NLL Loss @ epoch 0020 iteration 00000080 = 0.25199589133262634\n",
            "INFO  | 2023-02-10 19:50:01,930 | gran_runner.py            | line 266  : NLL Loss @ epoch 0023 iteration 00000090 = 0.2275182455778122\n",
            "INFO  | 2023-02-10 19:50:09,278 | gran_runner.py            | line 266  : NLL Loss @ epoch 0025 iteration 00000100 = 0.2090468406677246\n",
            "INFO  | 2023-02-10 19:50:16,699 | gran_runner.py            | line 266  : NLL Loss @ epoch 0028 iteration 00000110 = 0.27084702253341675\n",
            "INFO  | 2023-02-10 19:50:24,221 | gran_runner.py            | line 266  : NLL Loss @ epoch 0030 iteration 00000120 = 0.2517250180244446\n",
            "INFO  | 2023-02-10 19:50:32,890 | gran_runner.py            | line 266  : NLL Loss @ epoch 0033 iteration 00000130 = 0.1918548047542572\n",
            "INFO  | 2023-02-10 19:50:39,441 | gran_runner.py            | line 266  : NLL Loss @ epoch 0035 iteration 00000140 = 0.21152439713478088\n",
            "INFO  | 2023-02-10 19:50:48,698 | gran_runner.py            | line 266  : NLL Loss @ epoch 0038 iteration 00000150 = 0.19847053289413452\n",
            "INFO  | 2023-02-10 19:50:55,759 | gran_runner.py            | line 266  : NLL Loss @ epoch 0040 iteration 00000160 = 0.23223339021205902\n",
            "INFO  | 2023-02-10 19:51:04,590 | gran_runner.py            | line 266  : NLL Loss @ epoch 0043 iteration 00000170 = 0.214239701628685\n",
            "INFO  | 2023-02-10 19:51:11,092 | gran_runner.py            | line 266  : NLL Loss @ epoch 0045 iteration 00000180 = 0.2074834406375885\n",
            "INFO  | 2023-02-10 19:51:19,821 | gran_runner.py            | line 266  : NLL Loss @ epoch 0048 iteration 00000190 = 0.25359806418418884\n",
            "INFO  | 2023-02-10 19:51:26,295 | gran_runner.py            | line 266  : NLL Loss @ epoch 0050 iteration 00000200 = 0.18955452740192413\n",
            "INFO  | 2023-02-10 19:51:35,063 | gran_runner.py            | line 266  : NLL Loss @ epoch 0053 iteration 00000210 = 0.21775050461292267\n",
            "INFO  | 2023-02-10 19:51:42,606 | gran_runner.py            | line 266  : NLL Loss @ epoch 0055 iteration 00000220 = 0.24356846511363983\n",
            "INFO  | 2023-02-10 19:51:50,601 | gran_runner.py            | line 266  : NLL Loss @ epoch 0058 iteration 00000230 = 0.19302824139595032\n",
            "INFO  | 2023-02-10 19:51:58,140 | gran_runner.py            | line 266  : NLL Loss @ epoch 0060 iteration 00000240 = 0.20519128441810608\n",
            "INFO  | 2023-02-10 19:52:06,213 | gran_runner.py            | line 266  : NLL Loss @ epoch 0063 iteration 00000250 = 0.2076866179704666\n",
            "INFO  | 2023-02-10 19:52:13,746 | gran_runner.py            | line 266  : NLL Loss @ epoch 0065 iteration 00000260 = 0.2030361145734787\n",
            "INFO  | 2023-02-10 19:52:22,523 | gran_runner.py            | line 266  : NLL Loss @ epoch 0068 iteration 00000270 = 0.15549591183662415\n",
            "INFO  | 2023-02-10 19:52:29,158 | gran_runner.py            | line 266  : NLL Loss @ epoch 0070 iteration 00000280 = 0.16763387620449066\n",
            "INFO  | 2023-02-10 19:52:38,026 | gran_runner.py            | line 266  : NLL Loss @ epoch 0073 iteration 00000290 = 0.20495347678661346\n",
            "INFO  | 2023-02-10 19:52:44,644 | gran_runner.py            | line 266  : NLL Loss @ epoch 0075 iteration 00000300 = 0.15830378234386444\n",
            "INFO  | 2023-02-10 19:52:53,723 | gran_runner.py            | line 266  : NLL Loss @ epoch 0078 iteration 00000310 = 0.156808003783226\n",
            "INFO  | 2023-02-10 19:53:00,230 | gran_runner.py            | line 266  : NLL Loss @ epoch 0080 iteration 00000320 = 0.150306835770607\n",
            "INFO  | 2023-02-10 19:53:09,259 | gran_runner.py            | line 266  : NLL Loss @ epoch 0083 iteration 00000330 = 0.13941965997219086\n",
            "INFO  | 2023-02-10 19:53:15,743 | gran_runner.py            | line 266  : NLL Loss @ epoch 0085 iteration 00000340 = 0.15409041941165924\n",
            "INFO  | 2023-02-10 19:53:24,850 | gran_runner.py            | line 266  : NLL Loss @ epoch 0088 iteration 00000350 = 0.1393352746963501\n",
            "INFO  | 2023-02-10 19:53:32,270 | gran_runner.py            | line 266  : NLL Loss @ epoch 0090 iteration 00000360 = 0.1425689309835434\n",
            "INFO  | 2023-02-10 19:53:40,232 | gran_runner.py            | line 266  : NLL Loss @ epoch 0093 iteration 00000370 = 0.12695609033107758\n",
            "INFO  | 2023-02-10 19:53:47,836 | gran_runner.py            | line 266  : NLL Loss @ epoch 0095 iteration 00000380 = 0.14928969740867615\n",
            "INFO  | 2023-02-10 19:53:56,077 | gran_runner.py            | line 266  : NLL Loss @ epoch 0098 iteration 00000390 = 0.1357557773590088\n",
            "INFO  | 2023-02-10 19:54:04,198 | gran_runner.py            | line 266  : NLL Loss @ epoch 0100 iteration 00000400 = 0.13270451128482819\n",
            "INFO  | 2023-02-10 19:54:12,733 | gran_runner.py            | line 266  : NLL Loss @ epoch 0103 iteration 00000410 = 0.13897667825222015\n",
            "INFO  | 2023-02-10 19:54:19,876 | gran_runner.py            | line 266  : NLL Loss @ epoch 0105 iteration 00000420 = 0.12123876065015793\n",
            "INFO  | 2023-02-10 19:54:28,948 | gran_runner.py            | line 266  : NLL Loss @ epoch 0108 iteration 00000430 = 0.13545598089694977\n",
            "INFO  | 2023-02-10 19:54:35,532 | gran_runner.py            | line 266  : NLL Loss @ epoch 0110 iteration 00000440 = 0.12030158191919327\n",
            "INFO  | 2023-02-10 19:54:44,639 | gran_runner.py            | line 266  : NLL Loss @ epoch 0113 iteration 00000450 = 0.14723782241344452\n",
            "INFO  | 2023-02-10 19:54:51,039 | gran_runner.py            | line 266  : NLL Loss @ epoch 0115 iteration 00000460 = 0.10060036182403564\n",
            "INFO  | 2023-02-10 19:55:00,013 | gran_runner.py            | line 266  : NLL Loss @ epoch 0118 iteration 00000470 = 0.1314077228307724\n",
            "INFO  | 2023-02-10 19:55:06,708 | gran_runner.py            | line 266  : NLL Loss @ epoch 0120 iteration 00000480 = 0.11250046640634537\n",
            "INFO  | 2023-02-10 19:55:15,808 | gran_runner.py            | line 266  : NLL Loss @ epoch 0123 iteration 00000490 = 0.12950289249420166\n",
            "INFO  | 2023-02-10 19:55:23,302 | gran_runner.py            | line 266  : NLL Loss @ epoch 0125 iteration 00000500 = 0.12375427782535553\n",
            "INFO  | 2023-02-10 19:55:31,355 | gran_runner.py            | line 266  : NLL Loss @ epoch 0128 iteration 00000510 = 0.11252733319997787\n",
            "INFO  | 2023-02-10 19:55:38,831 | gran_runner.py            | line 266  : NLL Loss @ epoch 0130 iteration 00000520 = 0.10355903208255768\n",
            "INFO  | 2023-02-10 19:55:46,665 | gran_runner.py            | line 266  : NLL Loss @ epoch 0133 iteration 00000530 = 0.09193619340658188\n",
            "INFO  | 2023-02-10 19:55:54,277 | gran_runner.py            | line 266  : NLL Loss @ epoch 0135 iteration 00000540 = 0.10857577621936798\n",
            "INFO  | 2023-02-10 19:56:03,140 | gran_runner.py            | line 266  : NLL Loss @ epoch 0138 iteration 00000550 = 0.11943335831165314\n",
            "INFO  | 2023-02-10 19:56:09,779 | gran_runner.py            | line 266  : NLL Loss @ epoch 0140 iteration 00000560 = 0.1341443508863449\n",
            "INFO  | 2023-02-10 19:56:18,717 | gran_runner.py            | line 266  : NLL Loss @ epoch 0143 iteration 00000570 = 0.09555035829544067\n",
            "INFO  | 2023-02-10 19:56:25,151 | gran_runner.py            | line 266  : NLL Loss @ epoch 0145 iteration 00000580 = 0.09892623871564865\n",
            "INFO  | 2023-02-10 19:56:34,128 | gran_runner.py            | line 266  : NLL Loss @ epoch 0148 iteration 00000590 = 0.105230413377285\n",
            "INFO  | 2023-02-10 19:56:40,577 | gran_runner.py            | line 266  : NLL Loss @ epoch 0150 iteration 00000600 = 0.111263707280159\n",
            "INFO  | 2023-02-10 19:56:49,511 | gran_runner.py            | line 266  : NLL Loss @ epoch 0153 iteration 00000610 = 0.08841323107481003\n",
            "INFO  | 2023-02-10 19:56:56,099 | gran_runner.py            | line 266  : NLL Loss @ epoch 0155 iteration 00000620 = 0.09662240743637085\n",
            "INFO  | 2023-02-10 19:57:06,352 | gran_runner.py            | line 266  : NLL Loss @ epoch 0158 iteration 00000630 = 0.10467095673084259\n",
            "INFO  | 2023-02-10 19:57:13,679 | gran_runner.py            | line 266  : NLL Loss @ epoch 0160 iteration 00000640 = 0.0984221026301384\n",
            "INFO  | 2023-02-10 19:57:21,483 | gran_runner.py            | line 266  : NLL Loss @ epoch 0163 iteration 00000650 = 0.09063874185085297\n",
            "INFO  | 2023-02-10 19:57:28,819 | gran_runner.py            | line 266  : NLL Loss @ epoch 0165 iteration 00000660 = 0.08639711141586304\n",
            "INFO  | 2023-02-10 19:57:36,774 | gran_runner.py            | line 266  : NLL Loss @ epoch 0168 iteration 00000670 = 0.10083651542663574\n",
            "INFO  | 2023-02-10 19:57:44,224 | gran_runner.py            | line 266  : NLL Loss @ epoch 0170 iteration 00000680 = 0.08714163303375244\n",
            "INFO  | 2023-02-10 19:57:53,107 | gran_runner.py            | line 266  : NLL Loss @ epoch 0173 iteration 00000690 = 0.10103563219308853\n",
            "INFO  | 2023-02-10 19:57:59,617 | gran_runner.py            | line 266  : NLL Loss @ epoch 0175 iteration 00000700 = 0.11451730877161026\n",
            "INFO  | 2023-02-10 19:58:08,554 | gran_runner.py            | line 266  : NLL Loss @ epoch 0178 iteration 00000710 = 0.10034551471471786\n",
            "INFO  | 2023-02-10 19:58:14,851 | gran_runner.py            | line 266  : NLL Loss @ epoch 0180 iteration 00000720 = 0.08664803206920624\n",
            "INFO  | 2023-02-10 19:58:23,705 | gran_runner.py            | line 266  : NLL Loss @ epoch 0183 iteration 00000730 = 0.09845995157957077\n",
            "INFO  | 2023-02-10 19:58:30,064 | gran_runner.py            | line 266  : NLL Loss @ epoch 0185 iteration 00000740 = 0.09959445148706436\n",
            "INFO  | 2023-02-10 19:58:38,774 | gran_runner.py            | line 266  : NLL Loss @ epoch 0188 iteration 00000750 = 0.07778779417276382\n",
            "INFO  | 2023-02-10 19:58:45,144 | gran_runner.py            | line 266  : NLL Loss @ epoch 0190 iteration 00000760 = 0.08487164974212646\n",
            "INFO  | 2023-02-10 19:58:53,938 | gran_runner.py            | line 266  : NLL Loss @ epoch 0193 iteration 00000770 = 0.09958343952894211\n",
            "INFO  | 2023-02-10 19:59:01,227 | gran_runner.py            | line 266  : NLL Loss @ epoch 0195 iteration 00000780 = 0.08789084106683731\n",
            "INFO  | 2023-02-10 19:59:09,161 | gran_runner.py            | line 266  : NLL Loss @ epoch 0198 iteration 00000790 = 0.08362626284360886\n",
            "INFO  | 2023-02-10 19:59:16,346 | gran_runner.py            | line 266  : NLL Loss @ epoch 0200 iteration 00000800 = 0.10908778011798859\n",
            "INFO  | 2023-02-10 19:59:24,266 | gran_runner.py            | line 266  : NLL Loss @ epoch 0203 iteration 00000810 = 0.09497356414794922\n",
            "INFO  | 2023-02-10 19:59:31,614 | gran_runner.py            | line 266  : NLL Loss @ epoch 0205 iteration 00000820 = 0.078303262591362\n",
            "INFO  | 2023-02-10 19:59:39,380 | gran_runner.py            | line 266  : NLL Loss @ epoch 0208 iteration 00000830 = 0.09005624800920486\n",
            "INFO  | 2023-02-10 19:59:46,701 | gran_runner.py            | line 266  : NLL Loss @ epoch 0210 iteration 00000840 = 0.07241970300674438\n",
            "INFO  | 2023-02-10 19:59:55,618 | gran_runner.py            | line 266  : NLL Loss @ epoch 0213 iteration 00000850 = 0.07972877472639084\n",
            "INFO  | 2023-02-10 20:00:02,107 | gran_runner.py            | line 266  : NLL Loss @ epoch 0215 iteration 00000860 = 0.09373434633016586\n",
            "INFO  | 2023-02-10 20:00:12,041 | gran_runner.py            | line 266  : NLL Loss @ epoch 0218 iteration 00000870 = 0.08286017179489136\n",
            "INFO  | 2023-02-10 20:00:18,404 | gran_runner.py            | line 266  : NLL Loss @ epoch 0220 iteration 00000880 = 0.08279862254858017\n",
            "INFO  | 2023-02-10 20:00:27,341 | gran_runner.py            | line 266  : NLL Loss @ epoch 0223 iteration 00000890 = 0.0767735093832016\n",
            "INFO  | 2023-02-10 20:00:33,792 | gran_runner.py            | line 266  : NLL Loss @ epoch 0225 iteration 00000900 = 0.07686888426542282\n",
            "INFO  | 2023-02-10 20:00:42,616 | gran_runner.py            | line 266  : NLL Loss @ epoch 0228 iteration 00000910 = 0.08427146077156067\n",
            "INFO  | 2023-02-10 20:00:49,001 | gran_runner.py            | line 266  : NLL Loss @ epoch 0230 iteration 00000920 = 0.08673427253961563\n",
            "INFO  | 2023-02-10 20:00:57,785 | gran_runner.py            | line 266  : NLL Loss @ epoch 0233 iteration 00000930 = 0.08105595409870148\n",
            "INFO  | 2023-02-10 20:01:05,351 | gran_runner.py            | line 266  : NLL Loss @ epoch 0235 iteration 00000940 = 0.07945164293050766\n",
            "INFO  | 2023-02-10 20:01:13,370 | gran_runner.py            | line 266  : NLL Loss @ epoch 0238 iteration 00000950 = 0.07012811303138733\n",
            "INFO  | 2023-02-10 20:01:20,711 | gran_runner.py            | line 266  : NLL Loss @ epoch 0240 iteration 00000960 = 0.07418594509363174\n",
            "INFO  | 2023-02-10 20:01:28,818 | gran_runner.py            | line 266  : NLL Loss @ epoch 0243 iteration 00000970 = 0.07170861959457397\n",
            "INFO  | 2023-02-10 20:01:36,238 | gran_runner.py            | line 266  : NLL Loss @ epoch 0245 iteration 00000980 = 0.07569365948438644\n",
            "INFO  | 2023-02-10 20:01:44,968 | gran_runner.py            | line 266  : NLL Loss @ epoch 0248 iteration 00000990 = 0.08926524966955185\n",
            "INFO  | 2023-02-10 20:01:51,570 | gran_runner.py            | line 266  : NLL Loss @ epoch 0250 iteration 00001000 = 0.07356280088424683\n",
            "INFO  | 2023-02-10 20:02:00,533 | gran_runner.py            | line 266  : NLL Loss @ epoch 0253 iteration 00001010 = 0.07400717586278915\n",
            "INFO  | 2023-02-10 20:02:07,009 | gran_runner.py            | line 266  : NLL Loss @ epoch 0255 iteration 00001020 = 0.06656914949417114\n",
            "INFO  | 2023-02-10 20:02:15,862 | gran_runner.py            | line 266  : NLL Loss @ epoch 0258 iteration 00001030 = 0.09054075181484222\n",
            "INFO  | 2023-02-10 20:02:22,320 | gran_runner.py            | line 266  : NLL Loss @ epoch 0260 iteration 00001040 = 0.06591381132602692\n",
            "INFO  | 2023-02-10 20:02:31,193 | gran_runner.py            | line 266  : NLL Loss @ epoch 0263 iteration 00001050 = 0.06289080530405045\n",
            "INFO  | 2023-02-10 20:02:37,715 | gran_runner.py            | line 266  : NLL Loss @ epoch 0265 iteration 00001060 = 0.07503961771726608\n",
            "INFO  | 2023-02-10 20:02:46,825 | gran_runner.py            | line 266  : NLL Loss @ epoch 0268 iteration 00001070 = 0.07379617542028427\n",
            "INFO  | 2023-02-10 20:02:54,078 | gran_runner.py            | line 266  : NLL Loss @ epoch 0270 iteration 00001080 = 0.06558497995138168\n",
            "INFO  | 2023-02-10 20:03:02,169 | gran_runner.py            | line 266  : NLL Loss @ epoch 0273 iteration 00001090 = 0.07231231778860092\n",
            "INFO  | 2023-02-10 20:03:09,616 | gran_runner.py            | line 266  : NLL Loss @ epoch 0275 iteration 00001100 = 0.06933530420064926\n",
            "INFO  | 2023-02-10 20:03:18,508 | gran_runner.py            | line 266  : NLL Loss @ epoch 0278 iteration 00001110 = 0.07607542723417282\n",
            "INFO  | 2023-02-10 20:03:25,749 | gran_runner.py            | line 266  : NLL Loss @ epoch 0280 iteration 00001120 = 0.06592776626348495\n",
            "INFO  | 2023-02-10 20:03:34,735 | gran_runner.py            | line 266  : NLL Loss @ epoch 0283 iteration 00001130 = 0.0681426152586937\n",
            "INFO  | 2023-02-10 20:03:41,132 | gran_runner.py            | line 266  : NLL Loss @ epoch 0285 iteration 00001140 = 0.08100396394729614\n",
            "INFO  | 2023-02-10 20:03:49,999 | gran_runner.py            | line 266  : NLL Loss @ epoch 0288 iteration 00001150 = 0.07754457741975784\n",
            "INFO  | 2023-02-10 20:03:56,532 | gran_runner.py            | line 266  : NLL Loss @ epoch 0290 iteration 00001160 = 0.07435489445924759\n",
            "INFO  | 2023-02-10 20:04:05,465 | gran_runner.py            | line 266  : NLL Loss @ epoch 0293 iteration 00001170 = 0.0762617215514183\n",
            "INFO  | 2023-02-10 20:04:11,915 | gran_runner.py            | line 266  : NLL Loss @ epoch 0295 iteration 00001180 = 0.06860630214214325\n",
            "INFO  | 2023-02-10 20:04:20,730 | gran_runner.py            | line 266  : NLL Loss @ epoch 0298 iteration 00001190 = 0.0703100934624672\n",
            "INFO  | 2023-02-10 20:04:27,169 | gran_runner.py            | line 266  : NLL Loss @ epoch 0300 iteration 00001200 = 0.06410731375217438\n",
            "INFO  | 2023-02-10 20:04:35,971 | gran_runner.py            | line 266  : NLL Loss @ epoch 0303 iteration 00001210 = 0.0778081938624382\n",
            "INFO  | 2023-02-10 20:04:43,571 | gran_runner.py            | line 266  : NLL Loss @ epoch 0305 iteration 00001220 = 0.06425900757312775\n",
            "INFO  | 2023-02-10 20:04:51,434 | gran_runner.py            | line 266  : NLL Loss @ epoch 0308 iteration 00001230 = 0.06350447982549667\n",
            "INFO  | 2023-02-10 20:04:58,686 | gran_runner.py            | line 266  : NLL Loss @ epoch 0310 iteration 00001240 = 0.06778959184885025\n",
            "INFO  | 2023-02-10 20:05:06,472 | gran_runner.py            | line 266  : NLL Loss @ epoch 0313 iteration 00001250 = 0.07622706145048141\n",
            "INFO  | 2023-02-10 20:05:13,867 | gran_runner.py            | line 266  : NLL Loss @ epoch 0315 iteration 00001260 = 0.07133294641971588\n",
            "INFO  | 2023-02-10 20:05:22,543 | gran_runner.py            | line 266  : NLL Loss @ epoch 0318 iteration 00001270 = 0.0719175934791565\n",
            "INFO  | 2023-02-10 20:05:29,071 | gran_runner.py            | line 266  : NLL Loss @ epoch 0320 iteration 00001280 = 0.06568758189678192\n",
            "INFO  | 2023-02-10 20:05:38,022 | gran_runner.py            | line 266  : NLL Loss @ epoch 0323 iteration 00001290 = 0.06598799675703049\n",
            "INFO  | 2023-02-10 20:05:44,384 | gran_runner.py            | line 266  : NLL Loss @ epoch 0325 iteration 00001300 = 0.06887222826480865\n",
            "INFO  | 2023-02-10 20:05:53,303 | gran_runner.py            | line 266  : NLL Loss @ epoch 0328 iteration 00001310 = 0.060926832258701324\n",
            "INFO  | 2023-02-10 20:05:59,761 | gran_runner.py            | line 266  : NLL Loss @ epoch 0330 iteration 00001320 = 0.07033387571573257\n",
            "INFO  | 2023-02-10 20:06:08,764 | gran_runner.py            | line 266  : NLL Loss @ epoch 0333 iteration 00001330 = 0.05819416046142578\n",
            "INFO  | 2023-02-10 20:06:15,021 | gran_runner.py            | line 266  : NLL Loss @ epoch 0335 iteration 00001340 = 0.07798459380865097\n",
            "INFO  | 2023-02-10 20:06:24,746 | gran_runner.py            | line 266  : NLL Loss @ epoch 0338 iteration 00001350 = 0.061125051230192184\n",
            "INFO  | 2023-02-10 20:06:31,767 | gran_runner.py            | line 266  : NLL Loss @ epoch 0340 iteration 00001360 = 0.06826954334974289\n",
            "INFO  | 2023-02-10 20:06:39,859 | gran_runner.py            | line 266  : NLL Loss @ epoch 0343 iteration 00001370 = 0.06855010986328125\n",
            "INFO  | 2023-02-10 20:06:47,319 | gran_runner.py            | line 266  : NLL Loss @ epoch 0345 iteration 00001380 = 0.06704434007406235\n",
            "ERROR | 2023-02-10 20:06:49,525 | run_exp.py                | line 42   : Traceback (most recent call last):\n",
            "  File \"run_exp.py\", line 38, in main\n",
            "    runner.train()\n",
            "  File \"/content/GRAN/runner/gran_runner.py\", line 255, in train\n",
            "    optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 23, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 234, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 300, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 412, in _single_tensor_adam\n",
            "    param.addcdiv_(exp_avg, denom, value=-step_size)\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jruTxwIT8YU9",
        "outputId": "3d03112b-db90-4838-8902-fb9194609fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mconfig\u001b[0m/   \u001b[01;32mdownload_model.sh\u001b[0m*  LICENSE    requirements.txt  \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/     \u001b[01;34mexp\u001b[0m/                \u001b[01;34mmodel\u001b[0m/     run_exp.py\n",
            "\u001b[01;34mdataset\u001b[0m/  __init__.py         README.md  \u001b[01;34mrunner\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model: ./exp/gran_grid/xxx/model_snapshot_best.pth\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "3TTFbF33kfZ2",
        "outputId": "07b34d27-152e-4e56-fb02-7d50893fcc42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-da6762341bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgran_grid\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mxxx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodel_snapshot_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIMB9IxRkfcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9uCZAsThoFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T06hto_GgS2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMOPpC21gS5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcT0C1HQgS70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcjnmTDOfN5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}