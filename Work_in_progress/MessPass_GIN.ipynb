{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMW00CUgA+GcojKojJUAO9v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmina98/PhD/blob/main/Work_in_progress/MessPass_GIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "u544FiWkIMCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgucepwTiKqg",
        "outputId": "518b3597-6e53-4e28-cc82-964bd45c515f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=ec89ecd6aaf79bfae711079f23cdcae9df0c5ee2abedbb58951f03cf591c6337\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n",
            "install: missing destination file operand after 'torch_geometric'\n",
            "Try 'install --help' for more information.\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install plotnine --quiet\n",
        "!pip install torch_geometric\n",
        "! install torch_geometric\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "metadata": {
        "id": "Lp5_AdSJi9X8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric \n",
        "from typing import Callable, List, Optional, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch import Tensor\n",
        "from torch.optim import Optimizer\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv,ChebConv\n",
        "#from torch_geometric.utils import accuracy\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from torch_geometric.utils import get_laplacian\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from plotnine import ggplot, geom_line, aes, xlab, theme, element_blank, ggtitle\n",
        "import scipy.sparse as sparse\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "R9T-RXjJVccy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# libary imports \n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import operator\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "from torch.optim.adadelta import Adadelta\n",
        "from torch.optim.adagrad import Adagrad\n",
        "from torch.optim.adam import Adam\n",
        "from torch.optim.adamax import Adamax\n",
        "from torch.optim.adamw import AdamW\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.optim.sgd import SGD\n",
        "\n",
        "import torch_geometric \n",
        "from typing import Callable, List, Optional, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch import Tensor\n",
        "from torch.optim import Optimizer\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv,ChebConv\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from torch_geometric.utils import get_laplacian\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from plotnine import ggplot, geom_line, aes, xlab, theme, element_blank, ggtitle\n",
        "import scipy.sparse as sparse\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from dataclasses import dataclass\n",
        "import torch_geometric.utils\n",
        "#from torch_geometric.utils import accuracy\n"
      ],
      "metadata": {
        "id": "LjSZvaHkTw5k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')\n"
      ],
      "metadata": {
        "id": "EDFDHjFSK64T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-r_NLLa8Lw7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset imports"
      ],
      "metadata": {
        "id": "DMM6naBmIQYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing targets for each dataset"
      ],
      "metadata": {
        "id": "oMHbOMJ3XZwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=list(range(3))\n",
        "i=0\n",
        "for dataset_name in ['Cora','CiteSeer','PubMed']:\n",
        "    dataset[i] = Planetoid('/tmp/dataset_name', name=dataset_name)\n",
        "    num_nodes = dataset[i].data.num_nodes\n",
        "    num_edges = dataset[i].data.num_edges // 2\n",
        "    train_len = dataset[i][0].train_mask.sum()\n",
        "    val_len = dataset[i][0].val_mask.sum()\n",
        "    test_len = dataset[i][0].test_mask.sum()\n",
        "    other_len = num_nodes - train_len - val_len - test_len\n",
        "    print(f\"Dataset: {dataset[i].name}\")\n",
        "    print(f\"Num. nodes: {num_nodes} (train={train_len}, val={val_len}, test={test_len}, other={other_len})\")\n",
        "    print(f\"Num. edges: {num_edges}\")\n",
        "    print(f\"Num. node features: {dataset[i].num_node_features}\")\n",
        "    print(f\"Num. classes: {dataset[i].num_classes}\")\n",
        "    print(f\"Dataset len.: {dataset[i].len()}\")\n",
        "    i=i+1\n",
        "    print(\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2iYQ5ggjCgm",
        "outputId": "a0b23c69-8634-494b-b565-49236ae62949"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Cora\n",
            "Num. nodes: 2708 (train=140, val=500, test=1000, other=1068)\n",
            "Num. edges: 5278\n",
            "Num. node features: 1433\n",
            "Num. classes: 7\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer\n",
            "Num. nodes: 3327 (train=120, val=500, test=1000, other=1707)\n",
            "Num. edges: 4552\n",
            "Num. node features: 3703\n",
            "Num. classes: 6\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: PubMed\n",
            "Num. nodes: 19717 (train=60, val=500, test=1000, other=18157)\n",
            "Num. edges: 44324\n",
            "Num. node features: 500\n",
            "Num. classes: 3\n",
            "Dataset len.: 1\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d={0:{}, 1:{}, 2:{}}\n",
        "for i in range(3):\n",
        "    data=dataset[i]\n",
        "    X_train=data[0].x[data[0].train_mask]\n",
        "    d[i]['X_train']=X_train\n",
        "    y_train=data[0].y[data[0].train_mask]\n",
        "    d[i]['y_train']=y_train\n",
        "    X_test=data[0].x[data[0].test_mask]\n",
        "    d[i]['X_test']=X_test\n",
        "    y_test=data[0].y[data[0].test_mask]\n",
        "    d[i]['y_test']=y_test\n",
        "    X_val=data[0].x[data[0].val_mask]\n",
        "    d[i]['X_val']=X_val\n",
        "    y_val=data[0].y[data[0].val_mask]\n",
        "    d[i]['y_val']=X_val\n"
      ],
      "metadata": {
        "id": "9b51MCcaXZO7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Message Passing "
      ],
      "metadata": {
        "id": "1R9Rv-5LOpav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_scatter import scatter_mean\n",
        "\n",
        "dataset[0].data\n",
        "x=dataset[0].data.x\n",
        "edge_index=dataset[0].data.edge_index\n",
        "x_j = x[edge_index[0]]  # Source node features [num_edges, num_features]\n",
        "x_i = x[edge_index[1]]  # Target node features [num_edges, num_features]"
      ],
      "metadata": {
        "id": "4_qSkwvTOylm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "class GIN(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()  \n",
        "        #initialisation\n",
        "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.flow = 'source_to_target'\n",
        "        self.out_channels=out_channels\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "        self.W1 = nn.Parameter(torch.zeros(size=(in_channels, out_channels))) #xavier paramiter inizializator\n",
        "        nn.init.xavier_uniform_(self.W1.data, gain=1.414)\n",
        "      \n",
        "\n",
        "    def mean_aggregate(self,x,edge_index):\n",
        "        row,col=edge_index\n",
        "        tmp = torch.index_select(x, 0, col) # shape [num_edges, embed_size)\n",
        "        aggr2 = scatter_mean(tmp,row,0)\n",
        "        return aggr2\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "       \n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        num_nodes=len(x)\n",
        "        # Step 1: Linearly transform node feature matrix.\n",
        "        #first term\n",
        "        first_term = self.lin(x)\n",
        "        \n",
        "        # Step 4-5: Start propagating messages.\n",
        "        out=self.collect(x,edge_index)\n",
        "        x_j=out['x_j']\n",
        "        out = self.message(x_j)\n",
        "        second_term= self.mean_aggregate(out,edge_index)\n",
        "        out=first_term + self.lin(second_term)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def collect(self ,x,edge_index):\n",
        "        i, j = (1, 0) if self.flow == 'source_to_target' else (0, 1)\n",
        "        out={}\n",
        "        # 2. construct message x_j, x_i. Both with shape [num_edge, embed_size]\n",
        "        out['x_j'] = x.index_select(0, edge_index[i]) \n",
        "        out['x_i'] = x.index_select(0, edge_index[j])\n",
        "        out['edge_index_i'] = edge_index[i] # Source node edges \n",
        "        out['edge_index_j'] = edge_index[j]   # Target node edges \n",
        "        return out  \n",
        "\n",
        "   \n",
        "    def message(self, x_j):\n",
        "        # x_j has shape [E, out_channels]\n",
        "        return  x_j\n",
        "    \n",
        "    #'not needed'\n",
        "    def update(self, aggr_out):\n",
        "    # aggr_out has shape [num_nodes, out_channels]\n",
        "\n",
        "    # Step 5: Return new node embeddings.\n",
        "        return aggr_out"
      ],
      "metadata": {
        "id": "DG_4EypPOyn-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = GIN(x.shape[1], 256)\n",
        "m=conv(x, edge_index)\n",
        "m"
      ],
      "metadata": {
        "id": "6mUFgn6v0Fiq",
        "outputId": "152e9c47-ee19-42d6-c4ae-8f74ac6f7f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0012,  0.0550, -0.1156,  ..., -0.0228,  0.0786,  0.0417],\n",
              "        [-0.0771,  0.1365, -0.0750,  ..., -0.0700,  0.0899, -0.0674],\n",
              "        [ 0.0017,  0.1060, -0.1788,  ..., -0.0507,  0.0400,  0.0582],\n",
              "        ...,\n",
              "        [ 0.0596,  0.0694, -0.0410,  ..., -0.0573,  0.1741,  0.0983],\n",
              "        [-0.0717,  0.1124, -0.1071,  ..., -0.0689,  0.0135, -0.1141],\n",
              "        [-0.0809,  0.0832, -0.0549,  ...,  0.0109,  0.0957,  0.0488]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXqQ-j7Nz9NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GINNet(torch.nn.Module):\n",
        "    def __init__(self,num_node_features, num_classes):\n",
        "       \n",
        "        super(GINNet, self).__init__()\n",
        "\n",
        "        num_features = num_node_features\n",
        "        num_classes=num_classes\n",
        "        dim = 32\n",
        "\n",
        "        nn1 = Sequential(Linear(num_features, dim), ReLU(), Linear(dim, dim))\n",
        "        self.conv1 = GINConv(nn1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
        "        self.conv2 = GINConv(nn2)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
        "        self.conv3 = GINConv(nn3)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
        "        self.conv4 = GINConv(nn4)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
        "        self.conv5 = GINConv(nn5)\n",
        "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "        self.fc1 = Linear(dim, dim)\n",
        "        self.fc2 = Linear(dim,num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch=None):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.conv4(x, edge_index))\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(self.conv5(x, edge_index))\n",
        "        x = self.bn5(x)\n",
        "        #x = global_add_pool(x, batch=0)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "QJBQjRCFz9PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GINNet(dataset[0].num_node_features, dataset[0].num_classes).to(device)\n",
        "print(GINNet(dataset[0].num_node_features, dataset[0].num_classes))\n",
        "print(GINNet(dataset[1].num_node_features, dataset[1].num_classes))\n",
        "print(GINNet(dataset[2].num_node_features, dataset[2].num_classes))"
      ],
      "metadata": {
        "id": "wiO6EQiy0FgY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}